{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "AVA-MLSP demo",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subpic/ava-mlsp/blob/master/predict_mlsp_wide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss3wYJoucEdt"
      },
      "source": [
        "### download libraries and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1EMX02gcSht"
      },
      "source": [
        "%%capture \n",
        "!pip install kuti\n",
        "!git clone https://github.com/subpic/ava-mlsp.git\n",
        "!wget -O ava-mlsp/models/irnv2_mlsp_wide_orig/model_best_weights.h5 https://www.dropbox.com/s/16k0vh1dn7ls0cd/model_best_weights.h5?dl=1&raw=1\n",
        "!pip install munch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mg58PzZhhQf"
      },
      "source": [
        "What follows is a trivially modified version of ava-mlsp/predict_mlsp_wide.ipynb:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym94loh-cEdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d002e0a3-2b00-4efa-a053-a9515e7eb0fa"
      },
      "source": [
        "import kuti\n",
        "from kuti import model_helper as mh\n",
        "from kuti import applications as apps\n",
        "from kuti import tensor_ops as ops\n",
        "from kuti import generic as gen\n",
        "from kuti import image_utils as img\n",
        "import pandas as pd, numpy as np, os"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Kuti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qv2CfY42cEdx"
      },
      "source": [
        "root_path = '/content/ava-mlsp/' # CHANGED to reflect PATH on colab\n",
        "\n",
        "dataset = root_path + 'metadata/AVA_data_official_test.csv';\n",
        "images_path = root_path + 'images/'\n",
        "ids = pd.read_csv(dataset)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_9cAO9z5GK0"
      },
      "source": [
        "# define the MLSP wide model (updated from kuti.applications)\n",
        "from kuti.applications import InceptionResNetV2, Lambda, tf, Concatenate, Model,\\\n",
        "Input, GlobalAveragePooling2D\n",
        "\n",
        "def model_inceptionresnet_pooled(input_shape=(None, None, 3), indexes=list(range(43)),\n",
        "                                 pool_size=(5, 5), name='', return_sizes=False):\n",
        "    \"\"\"\n",
        "    Returns the wide MLSP features, spatially pooled, from InceptionResNetV2.\n",
        "    * input_shape: shape of the input images\n",
        "    * indexes: indices of the modules to use\n",
        "    * pool_size: spatial extend of the MLSP features\n",
        "    * name: name of the model\n",
        "    * return_sizes: return the sizes of each layer: (model, pool_sizes)\n",
        "    :return: model or (model, pool_sizes)\n",
        "    \"\"\"\n",
        "\n",
        "    print('Loading InceptionResNetV2 multi-pooled with input_shape:', input_shape)\n",
        "    model_base = InceptionResNetV2(weights     = 'imagenet',\n",
        "                                   include_top = False,\n",
        "                                   input_shape = input_shape)\n",
        "    print('Creating multi-pooled model')\n",
        "\n",
        "    ImageResizer = Lambda(lambda x: tf.image.resize(x, pool_size),\n",
        "                          name='feature_resizer')\n",
        "\n",
        "    feature_layers = [l for l in model_base.layers if 'mixed' in l.name]\n",
        "    feature_layers = [feature_layers[i] for i in indexes]\n",
        "    pools = [ImageResizer(l.output) for l in feature_layers]\n",
        "    conc_pools = Concatenate(name='conc_pools', axis=3)(pools)\n",
        "\n",
        "    model = Model(inputs  = model_base.input, outputs = conc_pools)\n",
        "    if name: model.name = name\n",
        "\n",
        "    if return_sizes:\n",
        "        pool_sizes = [[np.int32(x) for x in f.get_shape()[1:]] for f in pools]\n",
        "        return model, pool_sizes\n",
        "    else:\n",
        "        return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRkeq0U6cEdz"
      },
      "source": [
        "### Load combined model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egb-bWNycEd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04f7c7cb-032d-4770-9c1a-86b3f65ea3d0"
      },
      "source": [
        "# load base model\n",
        "model_name = 'mlsp_wide_orig'\n",
        "input_shape = (None, None, 3)\n",
        "model_base = model_inceptionresnet_pooled(input_shape)\n",
        "pre = apps.process_input[apps.InceptionResNetV2]\n",
        "\n",
        "# MODEL DEF\n",
        "input_feats = Input(shape=(5,5,16928), dtype='float32')\n",
        "x = apps.inception_block(input_feats, size=1024)\n",
        "x = GlobalAveragePooling2D(name='final_GAP')(x)\n",
        "\n",
        "pred = apps.fc_layers(x, name       = 'head',\n",
        "                      fc_sizes      = [2048, 1024, 256,  1],\n",
        "                      dropout_rates = [0.25, 0.25, 0.5, 0],\n",
        "                      batch_norm    = 2)\n",
        "\n",
        "model = Model(inputs  = input_feats, \n",
        "              outputs = pred)\n",
        "\n",
        "gen_params = dict(batch_size    = 1,\n",
        "                  data_path     = images_path,                  \n",
        "                  process_fn    = pre,\n",
        "                  input_shape   = input_shape,\n",
        "                  inputs        = 'image_name',\n",
        "                  outputs       = 'MOS', \n",
        "                  fixed_batches = False)\n",
        "\n",
        "helper = mh.ModelHelper(model, model_name, ids, \n",
        "                        gen_params = gen_params)\n",
        "\n",
        "# load head model\n",
        "helper.load_model(model_name = root_path + 'models/irnv2_mlsp_wide_orig/model')\n",
        "\n",
        "# join base and head models\n",
        "helper.model = Model(inputs  = model_base.input, \n",
        "                     outputs = model(model_base.output))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading InceptionResNetV2 multi-pooled with input_shape: (None, None, 3)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "219062272/219055592 [==============================] - 1s 0us/step\n",
            "219070464/219055592 [==============================] - 1s 0us/step\n",
            "Creating multi-pooled model\n",
            "Model weights loaded: /content/ava-mlsp/models/irnv2_mlsp_wide_orig/model_best_weights.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTnpTloOcEd4"
      },
      "source": [
        "### Predict the score of a single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0XgHUxJcEd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b25eb1b-b275-494d-9f1a-f78d9611ee97"
      },
      "source": [
        "# choose an image from the test set\n",
        "image_path = images_path + ids[ids.set == 'test'].iloc[0].image_name\n",
        "\n",
        "# load, pre-process it, and pass it to the model\n",
        "I = pre( img.read_image(image_path) )\n",
        "I = np.expand_dims(I, 0)\n",
        "I_score = helper.model.predict(I)\n",
        "\n",
        "print('predicted image score:', I_score[0][0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted image score: 6.543146\n"
          ]
        }
      ]
    }
  ]
}